<!DOCTYPE html>
<html>
<head>
  <title>MediaPipe Face Tracking WebAR</title>
  <style>
    body { margin: 0; overflow: hidden; }
    video, canvas { position: absolute; top: 0; left: 0; }
  </style>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/face_mesh.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils/camera_utils.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/three@0.153.0/build/three.min.js"></script>
</head>
<body>

<video class="input_video" autoplay playsinline muted style="display:none;"></video>
<canvas class="output_canvas" width="1280" height="720"></canvas>

<script>
  const videoElement = document.querySelector('.input_video');
  const canvasElement = document.querySelector('.output_canvas');
  const canvasCtx = canvasElement.getContext('2d');

  // Set up FaceMesh
  const faceMesh = new FaceMesh({
    locateFile: (file) => `https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/${file}`
  });

  faceMesh.setOptions({
    maxNumFaces: 1,
    refineLandmarks: true,
    minDetectionConfidence: 0.5,
    minTrackingConfidence: 0.5
  });

  // THREE.js setup
  const scene = new THREE.Scene();
  const camera = new THREE.PerspectiveCamera(75, canvasElement.width / canvasElement.height, 0.1, 1000);
  const renderer = new THREE.WebGLRenderer({ canvas: canvasElement, alpha: true });
  renderer.setSize(canvasElement.width, canvasElement.height);

  const cube = new THREE.Mesh(
    new THREE.BoxGeometry(0.1, 0.1, 0.1),
    new THREE.MeshBasicMaterial({ color: 0xff0000 })
  );
  scene.add(cube);
  camera.position.z = 1;

  function onResults(results) {
    canvasCtx.clearRect(0, 0, canvasElement.width, canvasElement.height);

    if (results.multiFaceLandmarks && results.multiFaceLandmarks.length > 0) {
      const face = results.multiFaceLandmarks[0];

      // Get the nose tip landmark (landmark 1)
      const nose = face[1];

      // Update cube position
      cube.position.set(
        (nose.x - 0.5) * 2,  // Center x
        -(nose.y - 0.5) * 2, // Center y
        -nose.z              // Depth
      );
    }

    renderer.render(scene, camera);
  }

  faceMesh.onResults(onResults);

  // Start the camera
  const cameraUtils = new Camera(videoElement, {
    onFrame: async () => {
      await faceMesh.send({ image: videoElement });
    },
    width: 1280,
    height: 720
  });
  cameraUtils.start();
</script>

</body>
</html>
