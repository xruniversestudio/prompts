<!DOCTYPE html>
<html dir="rtl" lang="ar">
<head>
    <title>WebAR تجربة نظارات مع MediaPipe</title>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    
    <!-- Google Fonts -->
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Cairo:wght@400;700&display=swap" rel="stylesheet">
    
    <!-- Tailwind CSS -->
    <script src="https://cdn.tailwindcss.com"></script>

    <!-- MediaPipe Vision Task -->
    <script type="module" src="https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/vision_bundle.js"></script>
    
    <style>
        body {
            font-family: 'Cairo', sans-serif;
            margin: 0;
            overflow: hidden;
            background: #000;
        }
        
        #container {
            position: relative;
            width: 100vw;
            height: 100vh;
        }
        
        #video {
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            object-fit: cover;
            transform: scaleX(-1);
            z-index: 1;
        }
        
        #outputCanvas {
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            transform: scaleX(-1);
            z-index: 2;
            pointer-events: none;
        }
        
        .spinner {
            border: 4px solid rgba(255, 255, 255, 0.3);
            border-radius: 50%;
            border-top: 4px solid #fff;
            width: 40px;
            height: 40px;
            animation: spin 1s linear infinite;
        }
        
        @keyframes spin {
            0% { transform: rotate(0deg); }
            100% { transform: rotate(360deg); }
        }
        
        .debug-info {
            position: absolute;
            top: 10px;
            right: 10px;
            background: rgba(0,0,0,0.7);
            color: white;
            padding: 10px;
            border-radius: 5px;
            font-size: 12px;
            z-index: 10;
        }
    </style>
</head>
<body class="bg-gray-900 text-white">
    <!-- Container for video and canvas -->
    <div id="container">
        <video id="video" autoplay playsinline muted></video>
        <canvas id="outputCanvas"></canvas>
    </div>

    <!-- Debug Info -->
    <div id="debugInfo" class="debug-info hidden">
        <div>الحالة: <span id="status">غير متصل</span></div>
        <div>الوجوه المكتشفة: <span id="faceCount">0</span></div>
        <div>FPS: <span id="fps">0</span></div>
    </div>

    <!-- UI Container -->
    <div id="ui-container" class="absolute top-0 left-0 w-full h-full z-10 flex flex-col justify-center items-center p-4 bg-gray-900 bg-opacity-90">
        <!-- Start Button -->
        <div id="start-screen">
            <h1 class="text-4xl font-bold mb-4 text-center">تجربة النظارات الافتراضية</h1>
            <p class="text-lg mb-8 text-center">اضغط للبدء والسماح بالوصول إلى الكاميرا</p>
            <button id="startButton" class="bg-purple-600 hover:bg-purple-700 text-white font-bold py-4 px-8 rounded-full shadow-lg transform hover:scale-105 transition-transform duration-300 ease-in-out">
                ابدأ التجربة
            </button>
            <div class="mt-4">
                <label class="flex items-center justify-center">
                    <input type="checkbox" id="debugMode" class="mr-2">
                    <span>عرض معلومات التشخيص</span>
                </label>
            </div>
        </div>

        <!-- Loading message -->
        <div id="loadingMessage" class="hidden bg-black bg-opacity-70 rounded-lg p-6 text-center">
            <div class="spinner mx-auto mb-4"></div>
            <h2 class="text-2xl font-bold mb-2">جاري التحميل...</h2>
            <p id="loading-text">يرجى الانتظار...</p>
        </div>
    </div>

    <!-- Load Three.js -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/three.js/r128/three.min.js"></script>
    
    <script type="module">
        import { FaceLandmarker, FilesetResolver } from "https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/vision_bundle.js";

        // DOM Elements
        const videoElement = document.getElementById('video');
        const canvasElement = document.getElementById('outputCanvas');
        const uiContainer = document.getElementById('ui-container');
        const startScreen = document.getElementById('start-screen');
        const loadingMessage = document.getElementById('loadingMessage');
        const loadingText = document.getElementById('loading-text');
        const startButton = document.getElementById('startButton');
        const debugInfo = document.getElementById('debugInfo');
        const debugMode = document.getElementById('debugMode');
        
        // Status elements
        const statusEl = document.getElementById('status');
        const faceCountEl = document.getElementById('faceCount');
        const fpsEl = document.getElementById('fps');
        
        // Variables
        let faceLandmarker;
        let runningMode = "VIDEO";
        let glasses;
        let scene, camera, renderer;
        let isDebugMode = false;
        let lastTime = performance.now();
        let frameCount = 0;

        // Create Face Landmarker
        async function createFaceLandmarker() {
            loadingText.textContent = "جاري تحميل نماذج الذكاء الاصطناعي...";
            
            try {
                const filesetResolver = await FilesetResolver.forVisionTasks(
                    "https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@latest/wasm"
                );
                
                faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {
                    baseOptions: {
                        modelAssetPath: `https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task`,
                        delegate: "GPU"
                    },
                    outputFaceBlendshapes: false,
                    outputFacialTransformationMatrixes: true,
                    runningMode: runningMode,
                    numFaces: 1
                });
                
                console.log("✓ Face Landmarker model loaded successfully");
                return true;
            } catch (error) {
                console.error("✗ Failed to load Face Landmarker:", error);
                throw new Error("فشل في تحميل نموذج الذكاء الاصطناعي");
            }
        }

        // Setup Camera
        async function setupCamera() {
            loadingText.textContent = "في انتظار السماح بالوصول إلى الكاميرا...";
            
            try {
                const constraints = {
                    video: {
                        facingMode: 'user',
                        width: { ideal: 1280 },
                        height: { ideal: 720 }
                    }
                };
                
                const stream = await navigator.mediaDevices.getUserMedia(constraints);
                videoElement.srcObject = stream;
                
                return new Promise((resolve) => {
                    videoElement.addEventListener("loadeddata", () => {
                        console.log("✓ Camera setup successful");
                        console.log(`Video size: ${videoElement.videoWidth}x${videoElement.videoHeight}`);
                        resolve();
                    });
                });
            } catch (error) {
                console.error("✗ Camera setup failed:", error);
                throw new Error("فشل في الوصول إلى الكاميرا");
            }
        }

        // Initialize Three.js Scene
        function initThreeScene() {
            loadingText.textContent = "جاري إعداد المشهد ثلاثي الأبعاد...";
            
            try {
                // Scene
                scene = new THREE.Scene();
                
                // Camera - Match video aspect ratio
                const aspect = window.innerWidth / window.innerHeight;
                camera = new THREE.PerspectiveCamera(75, aspect, 0.01, 1000);
                camera.position.z = 1;
                
                // Renderer with proper transparency
                renderer = new THREE.WebGLRenderer({
                    canvas: canvasElement,
                    alpha: true,
                    premultipliedAlpha: false,
                    antialias: true
                });
                
                renderer.setPixelRatio(window.devicePixelRatio);
                renderer.setSize(window.innerWidth, window.innerHeight);
                renderer.autoClear = false;
                renderer.setClearColor(0x000000, 0); // Transparent background
                
                // Create glasses
                createGlasses();
                
                // Lighting
                const ambientLight = new THREE.AmbientLight(0xffffff, 0.6);
                scene.add(ambientLight);
                
                const directionalLight = new THREE.DirectionalLight(0xffffff, 0.8);
                directionalLight.position.set(0, 1, 1);
                scene.add(directionalLight);
                
                console.log("✓ Three.js scene initialized");
            } catch (error) {
                console.error("✗ Three.js initialization failed:", error);
                throw new Error("فشل في إعداد المشهد ثلاثي الأبعاد");
            }
        }

        // Create 3D Glasses
        function createGlasses() {
            glasses = new THREE.Group();
            
            // Frame material
            const frameMaterial = new THREE.MeshPhongMaterial({
                color: 0x333333,
                shininess: 100
            });
            
            // Lens material
            const lensMaterial = new THREE.MeshPhongMaterial({
                color: 0x000044,
                transparent: true,
                opacity: 0.3,
                shininess: 100
            });
            
            // Left and right lens frames
            const frameGeometry = new THREE.TorusGeometry(0.03, 0.003, 8, 16);
            
            const leftFrame = new THREE.Mesh(frameGeometry, frameMaterial);
            leftFrame.position.set(-0.035, 0, 0);
            glasses.add(leftFrame);
            
            const rightFrame = new THREE.Mesh(frameGeometry, frameMaterial);
            rightFrame.position.set(0.035, 0, 0);
            glasses.add(rightFrame);
            
            // Lenses
            const lensGeometry = new THREE.CircleGeometry(0.025, 16);
            
            const leftLens = new THREE.Mesh(lensGeometry, lensMaterial);
            leftLens.position.set(-0.035, 0, 0.001);
            glasses.add(leftLens);
            
            const rightLens = new THREE.Mesh(lensGeometry, lensMaterial);
            rightLens.position.set(0.035, 0, 0.001);
            glasses.add(rightLens);
            
            // Bridge
            const bridgeGeometry = new THREE.CylinderGeometry(0.002, 0.002, 0.02, 8);
            const bridge = new THREE.Mesh(bridgeGeometry, frameMaterial);
            bridge.rotation.z = Math.PI / 2;
            bridge.position.set(0, 0, 0);
            glasses.add(bridge);
            
            // Temples (arms)
            const templeGeometry = new THREE.CylinderGeometry(0.002, 0.002, 0.08, 8);
            
            const leftTemple = new THREE.Mesh(templeGeometry, frameMaterial);
            leftTemple.position.set(-0.065, 0, 0);
            leftTemple.rotation.z = Math.PI / 2;
            glasses.add(leftTemple);
            
            const rightTemple = new THREE.Mesh(templeGeometry, frameMaterial);
            rightTemple.position.set(0.065, 0, 0);
            rightTemple.rotation.z = Math.PI / 2;
            glasses.add(rightTemple);
            
            glasses.visible = false;
            scene.add(glasses);
        }

        // Main prediction loop
        let lastVideoTime = -1;
        function predictWebcam() {
            // Clear only depth buffer to maintain transparency
            renderer.clear(false, true, false);
            
            if (videoElement.currentTime !== lastVideoTime) {
                lastVideoTime = videoElement.currentTime;
                
                try {
                    const results = faceLandmarker.detectForVideo(videoElement, performance.now());
                    
                    if (results.facialTransformationMatrixes && results.facialTransformationMatrixes.length > 0) {
                        const matrix = results.facialTransformationMatrixes[0];
                        
                        if (isDebugMode) {
                            faceCountEl.textContent = results.facialTransformationMatrixes.length;
                            statusEl.textContent = "متصل ويعمل";
                        }
                        
                        // Apply transformation to glasses
                        glasses.visible = true;
                        applyFaceTransformation(matrix);
                        
                    } else {
                        glasses.visible = false;
                        if (isDebugMode) {
                            faceCountEl.textContent = "0";
                            statusEl.textContent = "لا يوجد وجوه مكتشفة";
                        }
                    }
                } catch (error) {
                    console.error("Prediction error:", error);
                    glasses.visible = false;
                }
            }
            
            // Update FPS counter
            if (isDebugMode) {
                frameCount++;
                const currentTime = performance.now();
                if (currentTime - lastTime >= 1000) {
                    fpsEl.textContent = frameCount;
                    frameCount = 0;
                    lastTime = currentTime;
                }
            }
            
            renderer.render(scene, camera);
            requestAnimationFrame(predictWebcam);
        }

        // Apply face transformation to glasses
        function applyFaceTransformation(transformMatrix) {
            const data = transformMatrix.data;
            
            // Create transformation matrix
            const matrix = new THREE.Matrix4();
            matrix.set(
                data[0], data[1], data[2], data[3],
                data[4], data[5], data[6], data[7],
                data[8], data[9], data[10], data[11],
                data[12], data[13], data[14], data[15]
            );
            
            // Apply matrix transformation
            glasses.matrix.copy(matrix);
            glasses.matrix.decompose(glasses.position, glasses.quaternion, glasses.scale);
            
            // Adjust scale and position for glasses
            const scaleFactor = 0.8;
            glasses.scale.multiplyScalar(scaleFactor);
            
            // Fine-tune position
            glasses.position.y += 0.01; // Move slightly up
            glasses.position.z -= 0.02; // Move slightly forward
        }

        // Start the experience
        async function startExperience() {
            startScreen.style.display = 'none';
            loadingMessage.classList.remove('hidden');
            
            isDebugMode = debugMode.checked;
            
            try {
                await createFaceLandmarker();
                await setupCamera();
                initThreeScene();
                
                // Start prediction loop
                predictWebcam();
                
                // Hide UI and show debug info if enabled
                uiContainer.style.display = 'none';
                if (isDebugMode) {
                    debugInfo.classList.remove('hidden');
                }
                
                console.log("✓ AR Glasses experience started successfully!");
                
            } catch (error) {
                console.error("✗ Initialization failed:", error);
                loadingText.innerHTML = `
                    <h2 class="text-2xl font-bold text-red-400 mb-2">فشل بدء التشغيل</h2>
                    <p class="text-red-300">${error.message}</p>
                    <button onclick="location.reload()" class="mt-4 bg-red-600 hover:bg-red-700 px-4 py-2 rounded">
                        إعادة المحاولة
                    </button>
                `;
            }
        }

        // Event listeners
        startButton.addEventListener('click', startExperience);

        // Handle window resize
        window.addEventListener('resize', () => {
            if (renderer && camera) {
                const width = window.innerWidth;
                const height = window.innerHeight;
                
                renderer.setSize(width, height);
                camera.aspect = width / height;
                camera.updateProjectionMatrix();
            }
        });

        // Handle orientation change
        window.addEventListener('orientationchange', () => {
            setTimeout(() => {
                if (renderer && camera) {
                    const width = window.innerWidth;
                    const height = window.innerHeight;
                    
                    renderer.setSize(width, height);
                    camera.aspect = width / height;
                    camera.updateProjectionMatrix();
                }
            }, 100);
        });
    </script>
</body>
</html>
