<!DOCTYPE html>
<html dir="rtl" lang="ar">
<head>
    <title>WebAR تجربة نظارات مع MediaPipe</title>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    
    <!-- Google Fonts -->
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Cairo:wght@400;700&display=swap" rel="stylesheet">
    
    <!-- Tailwind CSS -->
    <script src="https://cdn.tailwindcss.com"></script>

    <!-- MediaPipe Vision Task -->
    <script type="module" src="https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/vision_bundle.js"></script>
    
    <!-- Basic styling for the page -->
    <style>
        body {
            font-family: 'Cairo', sans-serif;
            margin: 0;
            overflow: hidden;
        }
        canvas {
            position: absolute;
            top: 0;
            left: 0;
        }
        #video, #outputCanvas {
            transform: scaleX(-1); /* Mirror the video and canvas */
        }
    </style>
</head>
<body class="bg-gray-900 text-white">
    <!-- Container for video and canvas to overlap -->
    <div id="container" class="relative w-full h-full">
        <video id="video" class="absolute inset-0 w-full h-full object-cover" autoplay playsinline></video>
        <canvas id="outputCanvas" class="absolute inset-0 w-full h-full"></canvas>
    </div>


    <!-- UI Container -->
    <div id="ui-container" class="absolute top-0 left-0 w-full h-full z-10 flex flex-col justify-center items-center p-4">
        <!-- Loading/Error message to inform the user -->
        <div id="loadingMessage" class="bg-black bg-opacity-50 rounded-lg p-6 text-center">
            <h2 class="text-2xl font-bold mb-2">جاري تحميل نماذج الذكاء الاصطناعي من Google...</h2>
            <p>يرجى الانتظار والسماح بالوصول إلى الكاميرا عند الطلب.</p>
        </div>
    </div>

    <!-- Load Three.js -->
    <script src="https://cdn.jsdelivr.net/npm/three@0.153.0/build/three.min.js"></script>
    
    <!-- Main application logic -->
    <script type="module">
        import { FaceLandmarker, FilesetResolver } from "https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/vision_bundle.js";

        const videoElement = document.getElementById('video');
        const canvasElement = document.getElementById('outputCanvas');
        const loadingMessage = document.getElementById('loadingMessage');
        
        let faceLandmarker;
        let runningMode = "VIDEO";
        let glasses;
        let scene, camera, renderer;

        async function createFaceLandmarker() {
            const filesetResolver = await FilesetResolver.forVisionTasks(
                "https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@latest/wasm"
            );
            faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {
                baseOptions: {
                    modelAssetPath: `https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task`,
                    delegate: "GPU"
                },
                outputFaceBlendshapes: false,
                outputFacialTransformationMatrixes: true,
                runningMode: runningMode,
                numFaces: 1
            });
            console.log("Face Landmarker model loaded.");
        }

        async function setupCamera() {
            try {
                const stream = await navigator.mediaDevices.getUserMedia({ video: { facingMode: 'user' } });
                videoElement.srcObject = stream;
                videoElement.addEventListener("loadeddata", predictWebcam);
            } catch (error) {
                console.error("Camera access denied:", error);
                loadingMessage.innerHTML = `<h2 class="text-2xl font-bold text-red-400">خطأ في الوصول إلى الكاميرا</h2><p>يرجى السماح بالوصول إلى الكاميرا في إعدادات المتصفح وإعادة تحميل الصفحة.</p>`;
            }
        }

        function initThreeScene() {
            scene = new THREE.Scene();
            camera = new THREE.PerspectiveCamera(63, window.innerWidth / window.innerHeight, 0.1, 1000);
            renderer = new THREE.WebGLRenderer({
                canvas: canvasElement,
                alpha: true
            });
            renderer.setPixelRatio(window.devicePixelRatio);
            renderer.setSize(window.innerWidth, window.innerHeight);

            // Create the glasses geometry
            const glassesGroup = new THREE.Group();
            // A more modern/stylish glasses model
            const lensMaterial = new THREE.MeshPhysicalMaterial({
                color: 0x111111,
                transmission: 0.9,
                roughness: 0.1,
                ior: 1.5,
                thickness: 0.1,
                specularIntensity: 1,
                clearcoat: 1
            });

            const frameMaterial = new THREE.MeshStandardMaterial({
                color: 0x222222,
                metalness: 0.8,
                roughness: 0.2
            });

            const lensFrameGeometry = new THREE.TorusGeometry(0.07, 0.01, 16, 100);
            const leftFrame = new THREE.Mesh(lensFrameGeometry, frameMaterial);
            const rightFrame = new THREE.Mesh(lensFrameGeometry, frameMaterial);
            leftFrame.position.x = -0.08;
            rightFrame.position.x = 0.08;
            glassesGroup.add(leftFrame, rightFrame);
            
            const lensGeometry = new THREE.CircleGeometry(0.06, 32);
            const leftLens = new THREE.Mesh(lensGeometry, lensMaterial);
            const rightLens = new THREE.Mesh(lensGeometry, lensMaterial);
            leftLens.position.x = -0.08;
            rightLens.position.x = 0.08;
            glassesGroup.add(leftLens, rightLens);

            const bridgeGeometry = new THREE.CylinderGeometry(0.01, 0.01, 0.05, 8);
            const bridge = new THREE.Mesh(bridgeGeometry, frameMaterial);
            bridge.rotation.z = Math.PI / 2;
            glassesGroup.add(bridge);

            glassesGroup.visible = false;
            scene.add(glassesGroup);
            glasses = glassesGroup;

            // Add lighting
            const ambientLight = new THREE.AmbientLight(0xffffff, 0.8);
            scene.add(ambientLight);
            const directionalLight = new THREE.DirectionalLight(0xffffff, 1);
            directionalLight.position.set(0.5, 1, 1).normalize();
            scene.add(directionalLight);
        }

        let lastVideoTime = -1;
        async function predictWebcam() {
            // Adjust canvas size to match video aspect ratio
            const videoAspectRatio = videoElement.videoWidth / videoElement.videoHeight;
            const windowAspectRatio = window.innerWidth / window.innerHeight;
            if (videoAspectRatio > windowAspectRatio) {
                canvasElement.style.width = '100vw';
                canvasElement.style.height = 'auto';
            } else {
                canvasElement.style.height = '100vh';
                canvasElement.style.width = 'auto';
            }

            // Only run detection if the video frame has changed
            if (videoElement.currentTime !== lastVideoTime) {
                lastVideoTime = videoElement.currentTime;
                const results = faceLandmarker.detectForVideo(videoElement, performance.now());

                if (results.facialTransformationMatrixes && results.facialTransformationMatrixes.length > 0) {
                    const matrix = results.facialTransformationMatrixes[0].data;
                    glasses.visible = true;
                    // Apply the transformation matrix from MediaPipe to the glasses
                    glasses.matrix.fromArray(matrix);
                    glasses.matrix.decompose(glasses.position, glasses.quaternion, glasses.scale);
                    
                    // Adjust scale and position to fit better
                    glasses.scale.multiplyScalar(0.0011); // Adjust scale for the model
                    glasses.position.z -= 0.03; // Move glasses slightly forward

                } else {
                    glasses.visible = false;
                }
            }

            // Render the Three.js scene
            renderer.render(scene, camera);
            requestAnimationFrame(predictWebcam);
        }

        async function main() {
            await createFaceLandmarker();
            await setupCamera();
            initThreeScene();
            loadingMessage.style.display = 'none';
        }

        window.addEventListener('resize', () => {
             if (renderer && camera) {
                renderer.setSize(window.innerWidth, window.innerHeight);
                camera.aspect = window.innerWidth / window.innerHeight;
                camera.updateProjectionMatrix();
             }
        });

        main();
    </script>
</body>
</html>
