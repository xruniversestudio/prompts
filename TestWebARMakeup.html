<!DOCTYPE html>
<html lang="ar">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>ØªØ¬Ø±Ø¨Ø© Ù…ÙƒÙŠØ§Ø¬ Ø§ÙØªØ±Ø§Ø¶ÙŠ</title>
  <style>
    body { margin: 0; overflow: hidden; background-color: #000; }
    video, canvas {
      position: absolute;
      top: 0; left: 0;
      width: 100%; height: 100%;
      object-fit: cover;
    }
    .status {
      position: absolute;
      bottom: 10px;
      left: 10px;
      color: white;
      background-color: rgba(0,0,0,0.5);
      padding: 5px 10px;
      border-radius: 5px;
      font-family: Arial, sans-serif;
    }
  </style>
</head>
<body>
  <video id="video" autoplay playsinline muted></video>
  <canvas id="overlay"></canvas>
  <div id="status" class="status">Ø¬Ø§Ø±ÙŠ Ø§Ù„ØªØ­Ù…ÙŠÙ„...</div>
  
  <!-- 1) ØªØ­Ù…ÙŠÙ„ TF.js Ø§Ù„ÙƒØ§Ù…Ù„ -->
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@latest"></script>
  <!-- 2) ØªØ­Ù…ÙŠÙ„ face-landmarks-detection -->
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/face-landmarks-detection@1.0.6/dist/face-landmarks-detection.min.js"></script>
  <script>
  // Ø¯Ø§Ù„Ø© Ù„ØªØ´ØºÙŠÙ„ Ø§Ù„ÙƒØ§Ù…ÙŠØ±Ø§ ÙˆØ¶Ù…Ø§Ù† play()
  async function setupCamera() {
    const video = document.getElementById('video');
    const status = document.getElementById('status');
    
    try {
      const stream = await navigator.mediaDevices.getUserMedia({ 
        video: { 
          width: { ideal: 640 },
          height: { ideal: 480 },
          facingMode: 'user'
        } 
      });
      
      video.srcObject = stream;
      
      return new Promise((resolve, reject) => {
        video.onloadedmetadata = () => {
          video.play()
            .then(() => {
              status.textContent = 'ØªÙ… ØªØ´ØºÙŠÙ„ Ø§Ù„ÙƒØ§Ù…ÙŠØ±Ø§';
              resolve(video);
            })
            .catch(err => {
              status.textContent = 'Ø®Ø·Ø£ ÙÙŠ ØªØ´ØºÙŠÙ„ Ø§Ù„ÙƒØ§Ù…ÙŠØ±Ø§: ' + err.message;
              reject(err);
            });
        };
        
        video.onerror = (err) => {
          status.textContent = 'Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„ÙƒØ§Ù…ÙŠØ±Ø§';
          reject(err);
        };
      });
    } catch (err) {
      status.textContent = 'Ù„Ù… ÙŠØªÙ… Ø§Ù„ÙˆØµÙˆÙ„ Ù„Ù„ÙƒØ§Ù…ÙŠØ±Ø§: ' + err.message;
      throw err;
    }
  }
  
  async function main() {
    const status = document.getElementById('status');
    
    try {
      // 1. Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„ÙƒØ§Ù…ÙŠØ±Ø§
      status.textContent = 'Ø¬Ø§Ø±ÙŠ ØªØ´ØºÙŠÙ„ Ø§Ù„ÙƒØ§Ù…ÙŠØ±Ø§...';
      const video = await setupCamera();
      
      // 2. Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ù€ canvas
      const canvas = document.getElementById('overlay');
      const ctx = canvas.getContext('2d');
      
      // Ø§Ù†ØªØ¸Ø± Ø­ØªÙ‰ ÙŠØªÙ… ØªØ­Ù…ÙŠÙ„ Ø£Ø¨Ø¹Ø§Ø¯ Ø§Ù„ÙÙŠØ¯ÙŠÙˆ
      function updateCanvasSize() {
        if (video.videoWidth > 0 && video.videoHeight > 0) {
          canvas.width = video.videoWidth;
          canvas.height = video.videoHeight;
          status.textContent = 'ØªÙ… ØªÙ‡ÙŠØ¦Ø© Ø§Ù„ÙƒØ§Ù…ÙŠØ±Ø§ ÙˆØ§Ù„ÙƒØ§Ù†ÙØ§Ø³';
        } else {
          setTimeout(updateCanvasSize, 100);
        }
      }
      updateCanvasSize();
      
      // 3. ØªÙ‡ÙŠØ¦Ø© TF.js Ùˆ backend
      status.textContent = 'Ø¬Ø§Ø±ÙŠ ØªØ­Ù…ÙŠÙ„ TensorFlow...';
      await tf.setBackend('webgl');
      await tf.ready();
      console.log('âœ”ï¸ TensorFlow ready, backend:', tf.getBackend());
      
      // 4. Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù€ detector
      status.textContent = 'Ø¬Ø§Ø±ÙŠ ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø§Ù„ÙˆØ¬ÙˆÙ‡...';
      const model = faceLandmarksDetection.SupportedModels.MediaPipeFaceMesh;
      const detector = await faceLandmarksDetection.createDetector(model, {
        runtime: 'tfjs',
        maxFaces: 1, // ÙƒØ´Ù ÙˆØ¬Ù‡ ÙˆØ§Ø­Ø¯ ÙÙ‚Ø· Ù„ØªØ­Ø³ÙŠÙ† Ø§Ù„Ø£Ø¯Ø§Ø¡
        refineLandmarks: true // Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ù†Ù‚Ø§Ø· Ø¯Ù‚ÙŠÙ‚Ø© Ù„Ù„Ø´ÙØªÙŠÙ† ÙˆØ§Ù„Ø¹ÙŠÙ†ÙŠÙ†
      });
      console.log('âœ”ï¸ Detector initialized');
      status.textContent = 'Ø¬Ø§Ø±ÙŠ Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„ÙˆØ¬ÙˆÙ‡...';
      
      // 5. Ø­Ù„Ù‚Ø© Ø§Ù„Ø±Ø³Ù… ÙˆØ§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©
      async function renderLoop() {
        // ØªØ­Ø¯ÙŠØ« Ø­Ø¬Ù… Ø§Ù„ÙƒØ§Ù†ÙØ§Ø³ Ø¥Ø°Ø§ ØªØºÙŠØ± Ø­Ø¬Ù… Ø§Ù„ÙÙŠØ¯ÙŠÙˆ
        if (canvas.width !== video.videoWidth || canvas.height !== video.videoHeight) {
          canvas.width = video.videoWidth;
          canvas.height = video.videoHeight;
        }
        
        ctx.clearRect(0, 0, canvas.width, canvas.height);
        ctx.drawImage(video, 0, 0, canvas.width, canvas.height);
        
        try {
          // ØªÙ‚Ø¯ÙŠØ± Ø§Ù„ÙˆØ¬ÙˆÙ‡
          const faces = await detector.estimateFaces(video);
          console.log('Faces detected:', faces.length);
          
          if (faces.length > 0) {
            status.textContent = `ØªÙ… Ø§ÙƒØªØ´Ø§Ù ${faces.length} ÙˆØ¬Ù‡`;
            
            faces.forEach(face => {
              // Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ù†Ù‚Ø§Ø· Ø§Ù„Ø´ÙØªÙŠÙ†
              if (face.annotations && face.annotations.lipsUpperOuter && face.annotations.lipsLowerOuter) {
                // Ø±Ø³Ù… Ø£Ø­Ù…Ø± Ø§Ù„Ø´ÙØ§Ù‡
                const upper = face.annotations.lipsUpperOuter;
                const lower = face.annotations.lipsLowerOuter.slice().reverse();
                const lipPath = upper.concat(lower);
                
                ctx.beginPath();
                lipPath.forEach(([x, y], i) => i===0 ? ctx.moveTo(x, y) : ctx.lineTo(x, y));
                ctx.closePath();
                ctx.fillStyle = 'rgba(180,20,40,0.5)';
                ctx.fill();
              }
              
              // Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ù†Ù‚Ø§Ø· Ø§Ù„Ø®Ø¯ÙŠÙ†
              if (face.annotations && face.annotations.leftCheek && face.annotations.rightCheek) {
                // Ø±Ø³Ù… Ø£Ø­Ù…Ø± Ø§Ù„Ø®Ø¯ÙˆØ¯
                [face.annotations.leftCheek[0], face.annotations.rightCheek[0]]
                  .forEach(([x, y]) => {
                    ctx.beginPath();
                    ctx.arc(x, y, 30, 0, Math.PI * 2);
                    ctx.fillStyle = 'rgba(255,102,178,0.3)';
                    ctx.fill();
                  });
              }
            });
          } else {
            status.textContent = 'Ù„Ù… ÙŠØªÙ… Ø§ÙƒØªØ´Ø§Ù Ø£ÙŠ ÙˆØ¬Ù‡';
          }
        } catch (err) {
          console.error('Error in face detection:', err);
          status.textContent = 'Ø®Ø·Ø£ ÙÙŠ ÙƒØ´Ù Ø§Ù„ÙˆØ¬ÙˆÙ‡: ' + err.message;
        }
        
        requestAnimationFrame(renderLoop);
      }
      
      // Ø¨Ø¯Ø¡ Ø­Ù„Ù‚Ø© Ø§Ù„Ø±Ø³Ù… Ø¨Ø¹Ø¯ ØªØ£Ø®ÙŠØ± Ù‚ØµÙŠØ± Ù„Ø¶Ù…Ø§Ù† ØªØ­Ù…ÙŠÙ„ ÙƒÙ„ Ø´ÙŠØ¡
      setTimeout(renderLoop, 500);
      
    } catch (err) {
      console.error(err);
      status.textContent = 'Ø®Ø·Ø£: ' + err.message;
    }
  }
  
  // Ø¨Ø¯Ø¡ Ø§Ù„ØªØ·Ø¨ÙŠÙ‚
    window.addEventListener('load', main);
  </script>
</body>
</html><!DOCTYPE html>
<html lang="ar">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>ØªØ¬Ø±Ø¨Ø© Ù…ÙƒÙŠØ§Ø¬ Ø§ÙØªØ±Ø§Ø¶ÙŠ</title>
  <style>
    body { 
      margin: 0; 
      padding: 20px;
      background: #1a1a1a;
      color: white;
      font-family: Arial, sans-serif;
    }
    .container {
      max-width: 800px;
      margin: 0 auto;
      text-align: center;
    }
    .video-container {
      position: relative;
      margin: 20px 0;
      border-radius: 10px;
      overflow: hidden;
      box-shadow: 0 4px 20px rgba(0,0,0,0.3);
    }
    video, canvas {
      display: block;
      width: 100%;
      height: auto;
      max-width: 640px;
      max-height: 480px;
    }
    canvas {
      position: absolute;
      top: 0;
      left: 0;
    }
    .controls {
      margin: 20px 0;
    }
    button {
      background: linear-gradient(45deg, #ff6b6b, #ff8e53);
      border: none;
      padding: 12px 24px;
      margin: 5px;
      border-radius: 25px;
      color: white;
      cursor: pointer;
      font-size: 16px;
      transition: transform 0.2s;
    }
    button:hover {
      transform: scale(1.05);
    }
    button:disabled {
      opacity: 0.5;
      cursor: not-allowed;
      transform: none;
    }
    .status {
      margin: 10px 0;
      padding: 10px;
      background: rgba(255,255,255,0.1);
      border-radius: 10px;
      font-family: monospace;
    }
    .makeup-options {
      margin: 20px 0;
      display: flex;
      justify-content: center;
      gap: 10px;
      flex-wrap: wrap;
    }
    .makeup-btn {
      background: rgba(255,255,255,0.2);
      border: 2px solid transparent;
    }
    .makeup-btn.active {
      border-color: #ff6b6b;
      background: rgba(255,107,107,0.3);
    }
  </style>
</head>
<body>
  <div class="container">
    <h1>ğŸ¨ ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ù…ÙƒÙŠØ§Ø¬ Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠ</h1>
    
    <div class="controls">
      <button id="startBtn">ğŸ“¹ ØªØ´ØºÙŠÙ„ Ø§Ù„ÙƒØ§Ù…ÙŠØ±Ø§</button>
      <button id="stopBtn" disabled>â¹ï¸ Ø¥ÙŠÙ‚Ø§Ù Ø§Ù„ÙƒØ§Ù…ÙŠØ±Ø§</button>
    </div>

    <div class="makeup-options">
      <button class="makeup-btn" id="lipstickBtn">ğŸ’‹ Ø£Ø­Ù…Ø± Ø§Ù„Ø´ÙØ§Ù‡</button>
      <button class="makeup-btn" id="blushBtn">ğŸŒ¸ Ø£Ø­Ù…Ø± Ø§Ù„Ø®Ø¯ÙˆØ¯</button>
      <button class="makeup-btn" id="eyeshadowBtn">ğŸ‘ï¸ Ø¸Ù„Ø§Ù„ Ø§Ù„Ø¹ÙŠÙˆÙ†</button>
      <button class="makeup-btn" id="clearBtn">ğŸ§¹ Ù…Ø³Ø­ Ø§Ù„ÙƒÙ„</button>
    </div>

    <div class="status" id="status">Ø§Ø¶ØºØ· Ø¹Ù„Ù‰ ØªØ´ØºÙŠÙ„ Ø§Ù„ÙƒØ§Ù…ÙŠØ±Ø§ Ù„Ù„Ø¨Ø¯Ø¡</div>

    <div class="video-container">
      <video id="video" autoplay playsinline muted style="display: none;"></video>
      <canvas id="overlay"></canvas>
    </div>
  </div>

  <!-- TensorFlow.js -->
  <script src="https://cdnjs.cloudflare.com/ajax/libs/tensorflow/4.15.0/tf.min.js"></script>
  <!-- Face Detection Model -->
  <script src="https://cdnjs.cloudflare.com/ajax/libs/face-api.js/0.22.2/face-api.min.js"></script>

  <script>
    let video, canvas, ctx;
    let stream = null;
    let isRunning = false;
    let detectionInterval = null;
    
    // Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ù…ÙƒÙŠØ§Ø¬
    const makeupSettings = {
      lipstick: true,
      blush: true,
      eyeshadow: false
    };

    // Ø¹Ù†Ø§ØµØ± DOM
    const startBtn = document.getElementById('startBtn');
    const stopBtn = document.getElementById('stopBtn');
    const status = document.getElementById('status');
    const lipstickBtn = document.getElementById('lipstickBtn');
    const blushBtn = document.getElementById('blushBtn');
    const eyeshadowBtn = document.getElementById('eyeshadowBtn');
    const clearBtn = document.getElementById('clearBtn');

    // ØªØ­Ø¯ÙŠØ« Ø­Ø§Ù„Ø© Ø§Ù„Ø£Ø²Ø±Ø§Ø±
    function updateButtons() {
      lipstickBtn.classList.toggle('active', makeupSettings.lipstick);
      blushBtn.classList.toggle('active', makeupSettings.blush);
      eyeshadowBtn.classList.toggle('active', makeupSettings.eyeshadow);
    }

    // Ø£Ø­Ø¯Ø§Ø« Ø§Ù„Ø£Ø²Ø±Ø§Ø±
    startBtn.addEventListener('click', startCamera);
    stopBtn.addEventListener('click', stopCamera);
    
    lipstickBtn.addEventListener('click', () => {
      makeupSettings.lipstick = !makeupSettings.lipstick;
      updateButtons();
    });
    
    blushBtn.addEventListener('click', () => {
      makeupSettings.blush = !makeupSettings.blush;
      updateButtons();
    });
    
    eyeshadowBtn.addEventListener('click', () => {
      makeupSettings.eyeshadow = !makeupSettings.eyeshadow;
      updateButtons();
    });
    
    clearBtn.addEventListener('click', () => {
      makeupSettings.lipstick = false;
      makeupSettings.blush = false;
      makeupSettings.eyeshadow = false;
      updateButtons();
    });

    // ØªØ´ØºÙŠÙ„ Ø§Ù„ÙƒØ§Ù…ÙŠØ±Ø§
    async function startCamera() {
      try {
        status.textContent = 'ğŸ”„ Ø¬Ø§Ø±ÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬...';
        
        // ØªØ­Ù…ÙŠÙ„ Ù†Ù…Ø§Ø°Ø¬ face-api.js
        await loadModels();
        
        status.textContent = 'ğŸ“¹ Ø¬Ø§Ø±ÙŠ ØªØ´ØºÙŠÙ„ Ø§Ù„ÙƒØ§Ù…ÙŠØ±Ø§...';
        
        video = document.getElementById('video');
        canvas = document.getElementById('overlay');
        ctx = canvas.getContext('2d');

        // Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø¥Ø°Ù† Ø§Ù„ÙƒØ§Ù…ÙŠØ±Ø§
        stream = await navigator.mediaDevices.getUserMedia({ 
          video: { 
            width: 640, 
            height: 480,
            facingMode: 'user'
          } 
        });
        
        video.srcObject = stream;
        
        await new Promise(resolve => {
          video.onloadedmetadata = () => {
            canvas.width = video.videoWidth;
            canvas.height = video.videoHeight;
            video.style.display = 'block';
            resolve();
          };
        });

        await video.play();
        
        startBtn.disabled = true;
        stopBtn.disabled = false;
        isRunning = true;
        
        status.textContent = 'âœ… Ø¬Ø§Ø±ÙŠ Ø§Ù„ØªØ­Ù„ÙŠÙ„...';
        
        // Ø¨Ø¯Ø¡ Ø­Ù„Ù‚Ø© Ø§Ù„ØªØ­Ù„ÙŠÙ„
        startDetection();
        
      } catch (err) {
        console.error('Ø®Ø·Ø£ ÙÙŠ ØªØ´ØºÙŠÙ„ Ø§Ù„ÙƒØ§Ù…ÙŠØ±Ø§:', err);
        status.textContent = 'âŒ Ø®Ø·Ø£: ' + err.message;
      }
    }

    // Ø¥ÙŠÙ‚Ø§Ù Ø§Ù„ÙƒØ§Ù…ÙŠØ±Ø§
    function stopCamera() {
      if (stream) {
        stream.getTracks().forEach(track => track.stop());
        stream = null;
      }
      
      if (detectionInterval) {
        clearInterval(detectionInterval);
        detectionInterval = null;
      }
      
      video.style.display = 'none';
      ctx.clearRect(0, 0, canvas.width, canvas.height);
      
      startBtn.disabled = false;
      stopBtn.disabled = true;
      isRunning = false;
      
      status.textContent = 'ØªÙ… Ø¥ÙŠÙ‚Ø§Ù Ø§Ù„ÙƒØ§Ù…ÙŠØ±Ø§';
    }

    // ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬
    async function loadModels() {
      const MODEL_URL = 'https://cdnjs.cloudflare.com/ajax/libs/face-api.js/0.22.2/models';
      
      await Promise.all([
        faceapi.nets.tinyFaceDetector.loadFromUri(MODEL_URL),
        faceapi.nets.faceLandmark68Net.loadFromUri(MODEL_URL)
      ]);
    }

    // Ø¨Ø¯Ø¡ Ø¹Ù…Ù„ÙŠØ© Ø§Ù„ØªØ­Ù„ÙŠÙ„
    function startDetection() {
      detectionInterval = setInterval(async () => {
        if (!isRunning || !video || video.paused) return;
        
        await detectAndDraw();
      }, 100); // ÙƒÙ„ 100ms
    }

    // ØªØ­Ù„ÙŠÙ„ Ø§Ù„ÙˆØ¬Ù‡ ÙˆØ§Ù„Ø±Ø³Ù…
    async function detectAndDraw() {
      try {
        // Ù…Ø³Ø­ Ø§Ù„ÙƒØ§Ù†ÙØ§Ø³
        ctx.clearRect(0, 0, canvas.width, canvas.height);
        
        // ØªØ­Ù„ÙŠÙ„ Ø§Ù„ÙˆØ¬Ù‡
        const detections = await faceapi
          .detectAllFaces(video, new faceapi.TinyFaceDetectorOptions())
          .withFaceLandmarks();

        if (detections.length > 0) {
          status.textContent = `âœ… ØªÙ… Ø§ÙƒØªØ´Ø§Ù ${detections.length} ÙˆØ¬Ù‡`;
          
          detections.forEach(detection => {
            const landmarks = detection.landmarks;
            
            // Ø±Ø³Ù… Ø£Ø­Ù…Ø± Ø§Ù„Ø´ÙØ§Ù‡
            if (makeupSettings.lipstick) {
              drawLipstick(landmarks);
            }
            
            // Ø±Ø³Ù… Ø£Ø­Ù…Ø± Ø§Ù„Ø®Ø¯ÙˆØ¯
            if (makeupSettings.blush) {
              drawBlush(landmarks);
            }
            
            // Ø±Ø³Ù… Ø¸Ù„Ø§Ù„ Ø§Ù„Ø¹ÙŠÙˆÙ†
            if (makeupSettings.eyeshadow) {
              drawEyeshadow(landmarks);
            }
          });
        } else {
          status.textContent = 'ğŸ” Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† ÙˆØ¬ÙˆÙ‡...';
        }
        
      } catch (err) {
        console.error('Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ØªØ­Ù„ÙŠÙ„:', err);
        status.textContent = 'âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ØªØ­Ù„ÙŠÙ„';
      }
    }

    // Ø±Ø³Ù… Ø£Ø­Ù…Ø± Ø§Ù„Ø´ÙØ§Ù‡
    function drawLipstick(landmarks) {
      const mouth = landmarks.getMouth();
      
      ctx.fillStyle = 'rgba(220, 20, 60, 0.6)';
      ctx.beginPath();
      
      mouth.forEach((point, index) => {
        if (index === 0) {
          ctx.moveTo(point.x, point.y);
        } else {
          ctx.lineTo(point.x, point.y);
        }
      });
      
      ctx.closePath();
      ctx.fill();
    }

    // Ø±Ø³Ù… Ø£Ø­Ù…Ø± Ø§Ù„Ø®Ø¯ÙˆØ¯
    function drawBlush(landmarks) {
      const leftCheek = landmarks.getLeftCheek();
      const rightCheek = landmarks.getRightCheek();
      
      ctx.fillStyle = 'rgba(255, 182, 193, 0.4)';
      
      // Ø§Ù„Ø®Ø¯ Ø§Ù„Ø£ÙŠØ³Ø±
      if (leftCheek.length > 0) {
        const centerLeft = leftCheek[Math.floor(leftCheek.length / 2)];
        ctx.beginPath();
        ctx.arc(centerLeft.x, centerLeft.y, 25, 0, Math.PI * 2);
        ctx.fill();
      }
      
      // Ø§Ù„Ø®Ø¯ Ø§Ù„Ø£ÙŠÙ…Ù†
      if (rightCheek.length > 0) {
        const centerRight = rightCheek[Math.floor(rightCheek.length / 2)];
        ctx.beginPath();
        ctx.arc(centerRight.x, centerRight.y, 25, 0, Math.PI * 2);
        ctx.fill();
      }
    }

    // Ø±Ø³Ù… Ø¸Ù„Ø§Ù„ Ø§Ù„Ø¹ÙŠÙˆÙ†
    function drawEyeshadow(landmarks) {
      const leftEye = landmarks.getLeftEye();
      const rightEye = landmarks.getRightEye();
      
      ctx.fillStyle = 'rgba(138, 43, 226, 0.3)';
      
      // Ø§Ù„Ø¹ÙŠÙ† Ø§Ù„ÙŠØ³Ø±Ù‰
      if (leftEye.length > 0) {
        ctx.beginPath();
        leftEye.forEach((point, index) => {
          if (index === 0) {
            ctx.moveTo(point.x, point.y - 10);
          } else {
            ctx.lineTo(point.x, point.y - 5);
          }
        });
        ctx.closePath();
        ctx.fill();
      }
      
      // Ø§Ù„Ø¹ÙŠÙ† Ø§Ù„ÙŠÙ…Ù†Ù‰
      if (rightEye.length > 0) {
        ctx.beginPath();
        rightEye.forEach((point, index) => {
          if (index === 0) {
            ctx.moveTo(point.x, point.y - 10);
          } else {
            ctx.lineTo(point.x, point.y - 5);
          }
        });
        ctx.closePath();
        ctx.fill();
      }
    }

    // ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø£Ø²Ø±Ø§Ø± Ø¹Ù†Ø¯ Ø§Ù„ØªØ­Ù…ÙŠÙ„
    updateButtons();
  </script>
</body>
</html>
